{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 랭체인 프롬프트 작성(MessagesPlaceholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 이미지 보고서\n",
      "\n",
      "**개요:**\n",
      "\n",
      "이미지는 파이썬 코드를 보여줍니다. 코드 스니펫은 두 개의 가상 챗봇(앱등이와 삼엽충) 간의 논쟁을 시뮬레이션하는 데 사용되는 것으로 보입니다. 논쟁의 주제는 삼성과 애플 제품의 장단점입니다. 코드는 `langchain` 라이브러리를 사용하여 챗봇을 구축하고 OpenAI의 GPT-4o 모델을 사용하는 것으로 보입니다.\n",
      "\n",
      "**코드 내용 분석:**\n",
      "\n",
      "*   **변수 정의:** `bot2_reply = response2.content`와 `current_message = bot2_reply`는 챗봇의 응답을 저장하는 변수를 정의합니다.\n",
      "*   **출력:** `print(f\"{bot2_name}: {bot2_reply}\")`는 챗봇의 이름과 응답을 콘솔에 출력합니다.\n",
      "*   **챗봇 대화:** 이미지 중앙 부분은 실제로 챗봇 간의 대화 내용을 보여줍니다.  각 챗봇은 삼성과 애플 제품에 대한 극단적인 의견을 제시하며, 비속어와 공격적인 표현을 사용합니다.\n",
      "*   **라이브러리 임포트:** `import re`, `from langchain.schema import HumanMessage, SystemMessage`, `from langchain.chat_models import ChatOpenAI`는 코드에서 사용되는 라이브러리를 임포트합니다.\n",
      "*   **DebateBot 클래스:** `class DebateBot`는 챗봇 논쟁을 관리하는 데 사용되는 클래스를 정의합니다. `__init__` 메서드는 챗봇 모델과 온도(temperature)를 초기화합니다.\n",
      "\n",
      "**대화 내용 요약:**\n",
      "\n",
      "대화는 다음과 같은 특징을 보입니다.\n",
      "\n",
      "*   **극단적인 주장:** 각 챗봇은 자신의 선호 브랜드에 대해 극단적인 주장을 펼칩니다.\n",
      "*   **비속어 사용:** 대화에 비속어가 빈번하게 등장합니다.\n",
      "*   **인신 공격:** 상대방을 비난하는 인신 공격적인 발언이 나타납니다.\n",
      "*   **주요 논쟁점:** 삼성의 조잡함, 애플의 폐쇄성 및 감성 마케팅, 발열 문제, UI 디자인 등이 주요 논쟁점으로 등장합니다.\n",
      "\n",
      "**전반적인 분석:**\n",
      "\n",
      "이미지는 챗봇을 사용하여 삼성과 애플 제품에 대한 논쟁을 시뮬레이션하는 파이썬 코드를 보여줍니다. 챗봇 대화는 비속어와 인신 공격이 난무하는 형태로, 실제 사용자 간의 온라인 논쟁을 연상시킵니다. 코드는 `langchain` 라이브러리를 사용하여 챗봇을 구축하고 OpenAI의 GPT-4o 모델을 활용하는 것으로 보입니다. 하지만 대화의 질은 매우 낮고 건설적인 논쟁과는 거리가 멉니다.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\":[\n",
    "            {\n",
    "                \"type\":\"text\",\n",
    "                \"text\": \"이 이미지에 대한 보고서를 한글로 작성하세요\"\n",
    "            },\n",
    "            {\n",
    "                \"type\":\"image\",\n",
    "                \"source_type\":\"base64\",\n",
    "                \"mime_type\":\"image/png\",\n",
    "                \"data\":\"{image_data}\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "    \n",
    "])\n",
    "\n",
    "import base64\n",
    "img_path = r\"C:\\Users\\Sese\\Pictures\\Screenshots\\스크린샷 2025-06-07 195837.png\"\n",
    "img = open(img_path, \"rb\").read()\n",
    "image_data = base64.b64encode(img).decode('utf-8')\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\":\n",
    "            {\n",
    "                \"type\":\"text\",\n",
    "                \"text\":\"보고서의 형식은 다음과 같습니다:\\n\\n1. 제목\\n2. 요약\\n3. 주요 내용\\n4. 결론\"\n",
    "            }\n",
    "    }\n",
    "]\n",
    "\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"image_data\":image_data, \"messages\":[]})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tool 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "\n",
      "CODE:\n",
      "```python\n",
      "import random\n",
      "\n",
      "def generate_lotto_numbers():\n",
      "  \"\"\"Generates a set of 6 unique random numbers between 1 and 45 (inclusive).\"\"\"\n",
      "  return sorted(random.sample(range(1, 46), 6))\n",
      "\n",
      "print(generate_lotto_numbers())\n",
      "```\n",
      "[2, 10, 11, 15, 22, 40]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "python_tool = PythonREPLTool()\n",
    "\n",
    "print(python_tool.invoke(\"print(100+200)\"))\n",
    "\n",
    "def print_and_execute(code, debug=True):\n",
    "    if debug:\n",
    "        print(\"CODE:\")\n",
    "        print(code)\n",
    "    return python_tool.invoke(code)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": \"\"\"You are Raymond Hetting, an expert Python programmer.\n",
    "Generate only clean, executable Python code that runs correctly in an interactive REPL environment (no '__main__', no file-level guards).\n",
    "Write short, elegant, and PEP8-compliant code.\n",
    "Return only the code — no explanations, no markdown, no formatting.\"\"\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"{input}\"\n",
    "    }\n",
    "])\n",
    "\n",
    "\n",
    "chain = prompt | llm | StrOutputParser() | RunnableLambda(print_and_execute)\n",
    "print(chain.invoke(\"로또 번호 생성기를 출력하는 코드를 작성하세요.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a neo-classical painting that satirizes people looking at their smartphones. The scene should depict a grand, classical setting reminiscent of famous neoclassical artworks, with ornate columns and dramatic lighting. In the foreground, a diverse group of individuals—men and women of various ages and ethnicities—are engrossed in their smartphones, their expressions reflecting a mixture of fascination and detachment. In the background, traditional neoclassical figures such as philosophers and scholars are engaged in deep discussion, highlighting the contrast between their intellectual pursuits and the modern obsession with technology. The color palette should be rich and warm, with detailed textures, capturing the essence of neoclassicism while merging it with contemporary themes. Include subtle humorous elements, such as a statue looking disapprovingly at the scene, emphasizing the irony of the situation.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. \"\n",
    "    \"Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt\"\n",
    "    \"Output should be less than 1000 characters. Write in English only.\"\n",
    "    \"Image Description: \\n{image_desc}\",\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "image_prompt = chain.invoke(\n",
    "    {\"image_desc\":\"스마트폰을 바라보는 사람들을 풍자한 neo-classicism painting\"}\n",
    ")\n",
    "\n",
    "print(image_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-aVigf2W3LKDGsLzWGD4JJds8/user-423OeEihb0ZdztlQ3SmTtS5l/img-TWMKtyAqrkwXd9VcG7dqsJ18.png?st=2025-06-23T13%3A06%3A32Z&se=2025-06-23T15%3A06%3A32Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=8b33a531-2df9-46a3-bc02-d4b1430a422c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-06-23T02%3A17%3A35Z&ske=2025-06-24T02%3A17%3A35Z&sks=b&skv=2024-08-04&sig=5RVTv34eQYWCgeWnDm5Wz7ZM5AOOqBDItuct0/ZWVEM%3D\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from IPython.display import Image\n",
    "\n",
    "dalle = DallEAPIWrapper(model=\"dall-e-3\", size=\"1024x1024\", quality=\"standard\", n=1)\n",
    "\n",
    "query = image_prompt\n",
    "image_url = dalle.run(chain.invoke({\"image_desc\":query}))\n",
    "\n",
    "Image(url=image_url, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-aVigf2W3LKDGsLzWGD4JJds8/user-423OeEihb0ZdztlQ3SmTtS5l/img-86bSS17GOXjcKvBww6WNLPFF.png?st=2025-06-23T13%3A37%3A33Z&se=2025-06-23T15%3A37%3A33Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=8b33a531-2df9-46a3-bc02-d4b1430a422c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-06-22T16%3A44%3A57Z&ske=2025-06-23T16%3A44%3A57Z&sks=b&skv=2024-08-04&sig=0tzqBZmcZL32meyCq30toslehl8PXUgN7VH05PjBA4o%3D\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Image\n",
    "\n",
    "dalle = DallEAPIWrapper(model=\"dall-e-3\", size=\"1024x1024\", quality=\"standard\", n=1)\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "generate_image_url = RunnableLambda(lambda prompt: dalle.run(prompt))\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Generate a detailed IMAGE GENERATION prompt for DALL-E based on the following description. \"\n",
    "    \"Return only the prompt, no intro, no explanation, no chatty, no markdown, no code block, no nothing. Just the prompt\"\n",
    "    \"Output should be less than 1000 characters. Write in English only.\"\n",
    "    \"Image Description: \\n{image_desc}\",\n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser() | generate_image_url\n",
    "\n",
    "image_url = chain.invoke({\"image_desc\":\\\n",
    "    \"복귀자(감귤)와 미복귀자가 서로 다투는 4컷 만화\"})\n",
    "Image(url=image_url, width=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 사용자 정의 도구(Custom Tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_word_length', 'args': {'word': 'teddynote'}, 'id': 'e74fa9cf-9a95-42ad-b8ca-3771fa7a8f8e', 'type': 'tool_call'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.agents import tool\n",
    "\n",
    "\n",
    "# 도구를 정의합니다.\n",
    "@tool\n",
    "def get_word_length(word: str) -> int:\n",
    "    \"\"\"Returns the length of a word.\"\"\"\n",
    "    return len(word)\n",
    "\n",
    "\n",
    "@tool\n",
    "def add_function(a: float, b: float) -> float:\n",
    "    \"\"\"Adds two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def naver_news_crawl(news_url: str) -> str:\n",
    "    \"\"\"Crawls a 네이버 (naver.com) news article and returns the body content.\"\"\"\n",
    "    # HTTP GET 요청 보내기\n",
    "    response = requests.get(news_url)\n",
    "\n",
    "    # 요청이 성공했는지 확인\n",
    "    if response.status_code == 200:\n",
    "        # BeautifulSoup을 사용하여 HTML 파싱\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # 원하는 정보 추출\n",
    "        title = soup.find(\"h2\", id=\"title_area\").get_text()\n",
    "        content = soup.find(\"div\", id=\"contents\").get_text()\n",
    "        cleaned_title = re.sub(r\"\\n{2,}\", \"\\n\", title)\n",
    "        cleaned_content = re.sub(r\"\\n{2,}\", \"\\n\", content)\n",
    "    else:\n",
    "        print(f\"HTTP 요청 실패. 응답 코드: {response.status_code}\")\n",
    "\n",
    "    return f\"{cleaned_title}\\n{cleaned_content}\"\n",
    "\n",
    "\n",
    "tools = [get_word_length, add_function, naver_news_crawl]\n",
    "\n",
    "gemini = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "gemini_with_tools = gemini.bind_tools(tools)\n",
    "\n",
    "response = gemini_with_tools.invoke(\"What is the length of the word 'teddynote'?\")\n",
    "print(response.tool_calls)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '',\n",
       " 'additional_kwargs': {'function_call': {'name': 'get_word_length',\n",
       "   'arguments': '{\"word\": \"teddynote\"}'}},\n",
       " 'response_metadata': {'prompt_feedback': {'block_reason': 0,\n",
       "   'safety_ratings': []},\n",
       "  'finish_reason': 'STOP',\n",
       "  'model_name': 'gemini-2.0-flash',\n",
       "  'safety_ratings': []},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run--c90fca06-7793-45b0-8a73-1b85eecba3e9-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [{'name': 'get_word_length',\n",
       "   'args': {'word': 'teddynote'},\n",
       "   'id': 'e74fa9cf-9a95-42ad-b8ca-3771fa7a8f8e',\n",
       "   'type': 'tool_call'}],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 74,\n",
       "  'output_tokens': 9,\n",
       "  'total_tokens': 83,\n",
       "  'input_token_details': {'cache_read': 0}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[실행도구] get_word_length\n",
      "[실행결과] 9\n"
     ]
    }
   ],
   "source": [
    "def execute_tool_calls(tool_call_results):\n",
    "    \"\"\"\n",
    "    도구 호출 결과를 실행하는 함수\n",
    "\n",
    "    :param tool_call_results: 도구 호출 결과 리스트\n",
    "    :param tools: 사용 가능한 도구 리스트\n",
    "    \"\"\"\n",
    "    # 도구 호출 결과 리스트를 순회합니다.\n",
    "    for tool_call_result in tool_call_results:\n",
    "        # 도구의 이름과 인자를 추출합니다.\n",
    "        tool_name = tool_call_result[\"type\"]\n",
    "        tool_args = tool_call_result[\"args\"]\n",
    "\n",
    "        # 도구 이름과 일치하는 도구를 찾아 실행합니다.\n",
    "        # next() 함수를 사용하여 일치하는 첫 번째 도구를 찾습니다.\n",
    "        matching_tool = next((tool for tool in tools if tool.name == tool_name), None)\n",
    "\n",
    "        if matching_tool:\n",
    "            # 일치하는 도구를 찾았다면 해당 도구를 실행합니다.\n",
    "            result = matching_tool.invoke(tool_args)\n",
    "            # 실행 결과를 출력합니다.\n",
    "            print(f\"[실행도구] {tool_name}\\n[실행결과] {result}\")\n",
    "        else:\n",
    "            # 일치하는 도구를 찾지 못했다면 경고 메시지를 출력합니다.\n",
    "            print(f\"경고: {tool_name}에 해당하는 도구를 찾을 수 없습니다.\")\n",
    "\n",
    "\n",
    "from langchain_core.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "\n",
    "# 도구 바인딩 + 도구 파서\n",
    "chain = gemini_with_tools | JsonOutputToolsParser(tools=tools)\n",
    "\n",
    "# 실행 결과\n",
    "tool_call_results = chain.invoke(\"What is the length of the word 'teddynote'?\")\n",
    "\n",
    "execute_tool_calls(tool_call_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
