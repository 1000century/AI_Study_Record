{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "from datasets import Dataset\n",
        "from ragas import evaluate\n",
        "\n",
        "# .env 파일에서 환경 변수 로드\n",
        "load_dotenv()\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_chroma import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.5.0 which is incompatible.\n",
            "google-cloud-documentai-toolbox 0.14.2a0 requires Pillow<11.0.0,>=10.0.0, but you have pillow 11.1.0 which is incompatible.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\n",
            "llama-index-readers-file 0.4.6 requires beautifulsoup4<5.0.0,>=4.12.3, but you have beautifulsoup4 4.12.2 which is incompatible.\n",
            "llama-index-readers-file 0.4.6 requires pypdf<6.0.0,>=5.1.0, but you have pypdf 4.3.1 which is incompatible.\n",
            "markitdown-mcp 0.0.1a4 requires mcp~=1.8.0, but you have mcp 1.10.1 which is incompatible.\n",
            "notion-database 1.2.2 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
            "notion-database 1.2.2 requires urllib3<2.0, but you have urllib3 2.3.0 which is incompatible.\n",
            "pinecone-text 0.9.0 requires mmh3<5.0.0,>=4.1.0, but you have mmh3 5.1.0 which is incompatible.\n",
            "s3fs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "spyder 5.5.1 requires ipython!=8.17.1,<9.0.0,>=8.13.0; python_version > \"3.8\", but you have ipython 9.0.2 which is incompatible.\n",
            "transformers 4.48.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.19.1 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ragas\n",
            "  Downloading ragas-0.2.15-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: datasets in c:\\users\\sese\\anaconda3\\lib\\site-packages (2.20.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\sese\\anaconda3\\lib\\site-packages (from ragas) (1.26.4)\n",
            "Requirement already satisfied: tiktoken in c:\\users\\sese\\anaconda3\\lib\\site-packages (from ragas) (0.9.0)\n",
            "Requirement already satisfied: langchain in c:\\users\\sese\\anaconda3\\lib\\site-packages (from ragas) (0.3.26)\n",
            "Requirement already satisfied: langchain-core in c:\\users\\sese\\anaconda3\\lib\\site-packages (from ragas) (0.3.66)\n",
            "Requirement already satisfied: langchain-community in c:\\users\\sese\\anaconda3\\lib\\site-packages (from ragas) (0.3.26)\n",
            "Requirement already satisfied: langchain_openai in c:\\users\\sese\\anaconda3\\lib\\site-packages (from ragas) (0.3.24)\n",
            "Requirement already satisfied: nest-asyncio in c:\\users\\sese\\appdata\\roaming\\python\\python312\\site-packages (from ragas) (1.6.0)\n",
            "Requirement already satisfied: appdirs in c:\\users\\sese\\anaconda3\\lib\\site-packages (from ragas) (1.4.4)\n",
            "Requirement already satisfied: pydantic>=2 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from ragas) (2.11.7)\n",
            "Requirement already satisfied: openai>1 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from ragas) (1.88.0)\n",
            "Collecting diskcache>=5.6.3 (from ragas)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (15.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\sese\\appdata\\roaming\\python\\python312\\site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from openai>1->ragas) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from openai>1->ragas) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from openai>1->ragas) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from openai>1->ragas) (0.9.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\sese\\anaconda3\\lib\\site-packages (from openai>1->ragas) (1.3.1)\n",
            "Requirement already satisfied: certifi in c:\\users\\sese\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\sese\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from pydantic>=2->ragas) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from pydantic>=2->ragas) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from pydantic>=2->ragas) (0.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\sese\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langchain->ragas) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langchain->ragas) (0.3.45)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langchain->ragas) (2.0.39)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langchain-core->ragas) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langchain-core->ragas) (1.33)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.0.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain->ragas) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain->ragas) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain->ragas) (0.23.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langchain-community->ragas) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langchain-community->ragas) (2.8.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from langchain-community->ragas) (0.4.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from tiktoken->ragas) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sese\\appdata\\roaming\\python\\python312\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sese\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sese\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading ragas-0.2.15-py3-none-any.whl (190 kB)\n",
            "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Installing collected packages: requests, fsspec, diskcache, ragas\n",
            "\n",
            "  Attempting uninstall: requests\n",
            "\n",
            "    Found existing installation: requests 2.31.0\n",
            "\n",
            "    Uninstalling requests-2.31.0:\n",
            "\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\n",
            "   ---------------------------------------- 0/4 [requests]\n",
            "  Attempting uninstall: fsspec\n",
            "   ---------------------------------------- 0/4 [requests]\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "   ---------------------------------------- 0/4 [requests]\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "   ---------------------------------------- 0/4 [requests]\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "   ---------------------------------------- 0/4 [requests]\n",
            "   ---------- ----------------------------- 1/4 [fsspec]\n",
            "   ---------- ----------------------------- 1/4 [fsspec]\n",
            "   ---------- ----------------------------- 1/4 [fsspec]\n",
            "   ---------- ----------------------------- 1/4 [fsspec]\n",
            "   ------------------------------ --------- 3/4 [ragas]\n",
            "   ------------------------------ --------- 3/4 [ragas]\n",
            "   ------------------------------ --------- 3/4 [ragas]\n",
            "   ------------------------------ --------- 3/4 [ragas]\n",
            "   ---------------------------------------- 4/4 [ragas]\n",
            "\n",
            "Successfully installed diskcache-5.6.3 fsspec-2024.5.0 ragas-0.2.15 requests-2.32.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# 임베딩 모델 초기화 (OpenAI)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# LLM 초기화 (Google Gemini Flash)\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.0-flash\",\n",
        ")\n",
        "\n",
        "# ChromaDB 영속 디렉토리 설정\n",
        "PERSIST_DIRECTORY = \"C:\\\\Users\\\\Sese\\\\AI_Study_Record\\\\RAG_AGENT\\\\rag_0705\\\\chroma_db\"\n",
        "COLLECTION_NAME = \"html_docs\"\n",
        "\n",
        "# ChromaDB 로드 및 Retriever 생성\n",
        "db = Chroma(\n",
        "    persist_directory=PERSIST_DIRECTORY,\n",
        "    embedding_function=embeddings,\n",
        "    collection_name=COLLECTION_NAME,\n",
        ")\n",
        "retriever = db.as_retriever()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 평가 데이터셋 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 161 evaluation samples.\n",
            "First 3 samples:\n",
            "Sample 1: {'query': '이 문서에서 주로 다루는 증상은 무엇인가?', 'answer': '발열과 불명열', 'relevant_ids': ['63138f2a-6cd4-41e0-acb7-b4709755763f'], 'relevant_docs_metadata': [{'chunk_index': 0, 'chunk_metadata': \"{'Header 1': '#TITLE#'}\", 'source': 'C:\\\\Users\\\\Sese\\\\autosave\\\\알렌 이론 추출\\\\theory_texts\\\\1636_3826_발열, 불명열.html', 'total_chunks': 3}]}\n",
            "Sample 2: {'query': '발열의 가장 흔한 원인은 무엇인가요?', 'answer': '감염', 'relevant_ids': ['00d0c747-0aa7-4791-9130-b5b23af111a7'], 'relevant_docs_metadata': [{'chunk_index': 1, 'chunk_metadata': \"{'Header 1': '1. 발열(fever)'}\", 'source': 'C:\\\\Users\\\\Sese\\\\autosave\\\\알렌 이론 추출\\\\theory_texts\\\\1636_3826_발열, 불명열.html', 'total_chunks': 3}]}\n",
            "Sample 3: {'query': '불명열(FUO) 진단 시 FDG-PET/CT의 효용이 높은 이유는 무엇인가요?', 'answer': '암, 염증성 질환(혈관염 등)을 쉽게 확인할 수 있기 때문입니다.', 'relevant_ids': ['3eec88cf-e345-4494-ad92-2bec413b5b34'], 'relevant_docs_metadata': [{'chunk_index': 2, 'chunk_metadata': \"{'Header 1': '2. 불명열(fever of unknown origin, FUO)'}\", 'source': 'C:\\\\Users\\\\Sese\\\\autosave\\\\알렌 이론 추출\\\\theory_texts\\\\1636_3826_발열, 불명열.html', 'total_chunks': 3}]}\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"s1000secent/0705_rag_dataset\", token=os.environ.get(\"HUGGINGFACE_API_KEY\"))\n",
        "evaluation_data = dataset['0705']\n",
        "\n",
        "for sample in evaluation_data:\n",
        "    print(sample)\n",
        "    break\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "html_path = \"C:\\\\Users\\\\Sese\\\\autosave\\\\알렌 이론 추출\"\n",
        "\n",
        "def convert_to_list(example):\n",
        "    contexts = []\n",
        "    for idx, docs in enumerate(example['relevant_docs_metadata']):\n",
        "        context_source = docs['source']\n",
        "        context_path = os.path.join(html_path, context_source)\n",
        "        with open(context_path, 'r', encoding='utf-8') as f:\n",
        "            context_html = f.read()\n",
        "        contexts.append(context_html)\n",
        "    \n",
        "    return {\"contexts\":contexts, \"user_input\":example['query'], \"ground_truth\":example['answer']}\n",
        "\n",
        "dataset = dataset.map(convert_to_list)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. RAGAS를 이용한 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "724e9e56887a4323a36faf3c57fa7fd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/628 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[119]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-aVigf2W3LKDGsLzWGD4JJds8 on tokens per min (TPM): Limit 200000, Used 199327, Requested 1718. Please try again in 313ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[235]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-aVigf2W3LKDGsLzWGD4JJds8 on tokens per min (TPM): Limit 200000, Used 200000, Requested 1079. Please try again in 323ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[247]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-aVigf2W3LKDGsLzWGD4JJds8 on tokens per min (TPM): Limit 200000, Used 199476, Requested 1499. Please try again in 292ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[261]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-aVigf2W3LKDGsLzWGD4JJds8 on tokens per min (TPM): Limit 200000, Used 199267, Requested 3041. Please try again in 692ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[262]: TimeoutError()\n",
            "Exception raised in Job[287]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-aVigf2W3LKDGsLzWGD4JJds8 on tokens per min (TPM): Limit 200000, Used 200000, Requested 2295. Please try again in 688ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[306]: TimeoutError()\n",
            "Exception raised in Job[413]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-aVigf2W3LKDGsLzWGD4JJds8 on tokens per min (TPM): Limit 200000, Used 199394, Requested 2436. Please try again in 549ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[414]: TimeoutError()\n",
            "Exception raised in Job[474]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-aVigf2W3LKDGsLzWGD4JJds8 on tokens per min (TPM): Limit 200000, Used 199872, Requested 1895. Please try again in 530ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'answer_relevancy': 0.6919, 'faithfulness': 0.8438, 'context_recall': 0.8192, 'context_precision': 0.6885}\n"
          ]
        }
      ],
      "source": [
        "from ragas import evaluate\n",
        "\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
        "\n",
        "from langchain.callbacks.stdout import StdOutCallbackHandler\n",
        "from ragas import evaluate\n",
        "import os\n",
        "\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from openai import RateLimitError\n",
        "from ragas.llms import LangchainLLMWrapper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer_relevancy': 0.6919, 'faithfulness': 0.8438, 'context_recall': 0.8192, 'context_precision': 0.6885}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(os.getenv(\"GOOGLE_API_KEY\"))\n",
        "\n",
        "wrapped_llm = LangchainLLMWrapper(llm)\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6), retry_error_callback=lambda retry_state: print(\"최대 재시도 횟수 초과\"))\n",
        "def safe_evaluate():\n",
        "    return evaluate(\n",
        "        dataset=dataset['0705'],\n",
        "        metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],\n",
        "        llm = wrapped_llm\n",
        "    )\n",
        "\n",
        "\n",
        "result = safe_evaluate()\n",
        "\n",
        "result\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
