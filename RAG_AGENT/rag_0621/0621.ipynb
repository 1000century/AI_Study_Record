{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dbadb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "import yaml\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92892f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a32620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getenv(\"BASE_PATH\", default=\".\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", default=None)\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", default=None)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key = OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "vectordb_path = \"C://Users/Sese/AI_Study_Record/RAG_AGENT/rag_0621/chroma_db\"\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"html_docs\",\n",
    "    persist_directory=vectordb_path,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key=GOOGLE_API_KEY,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLSectionSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "]\n",
    "\n",
    "\n",
    "html_splitter = HTMLSectionSplitter(\n",
    "    headers_to_split_on=headers_to_split_on,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e908073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sese\\AI_Study_Record\\RAG_AGENT\\rag_0621\n"
     ]
    }
   ],
   "source": [
    "vectorstore_path = r\"C:\\Users\\Sese\\AI_Study_Record\\RAG_AGENT\\rag_0621\\chroma_db\"\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"html_docs\",\n",
    "    persist_directory=vectorstore_path,\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "\n",
    "# Î≤°ÌÑ∞Ïä§ÌÜ†Ïñ¥ÏôÄ retriever ÏÑ∏ÌåÖ\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 10}\n",
    ")\n",
    "\n",
    "print(os.getcwd())\n",
    "with open(\"queries.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    queries = yaml.safe_load(f).get(\"queries\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cf3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query: ÎéÖÍ∏∞Ïó¥Í≥º ÎπÑÏä∑Ìïú Îß§Í∞úÏ≤¥Î°ú Ïù∏Ìïú Í∞êÏóºÎ≥ëÏùÄ?\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2522_5676_Leptospira interrogans.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2522_5660_Vibrio spp..html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1757_4091_ÏöîÎ°úÍ∞êÏóº.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2747_5639_ÏóºÏ¶ùÏùò ÏñëÏÉÅ.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2521_5678_Pseudomonas aeruginosa.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2525_5684_Î™®Í∏∞ Îß§Í∞ú Í∞êÏóºÎ≥ë.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1643_3848_Ïó¨Ìñâ Í¥ÄÎ†® Î∞îÏù¥Îü¨Ïä§ Í∞êÏóº.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1640_3835_ÎÖπÎÜçÍ∑† Í∞êÏóº.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1778_4160_ÏúÑÏãùÎèÑÏó≠Î•òÏßàÌôò.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_3826_Î∞úÏó¥, Î∂àÎ™ÖÏó¥.html\n",
      "\n",
      "üîç Query: Î∂àÎ™ÖÏó¥ ÏßÑÎã® ÏàúÏÑúÎ•º ÏÑ§Î™ÖÌïòÏãúÏò§\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1698_3968_ÏÑùÌöåÌôî Í±¥Ïóº.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1698_3967_ÌöåÏ†ÑÍ∑ºÍ∞úÌååÏó¥.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_3826_Î∞úÏó¥, Î∂àÎ™ÖÏó¥.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\3442_5477_Í¥ÄÏ†àÏóºÏùò Í∞úÏöî.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1872_4389_ÏßÑÎã®ÏÑú.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1799_4205_ÏäπÎ™®Ìåê ÌÉàÏ∂ú.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1922_4462_Î¶ºÌîÑÏ¢Ö.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1643_3846_Ï§ëÏ¶ùÏó¥ÏÑ±ÌòàÏÜåÌåêÍ∞êÏÜåÏ¶ùÌõÑÍµ∞.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1925_4500_Ïú†Îüâ-Ïö©Îüâ Í≥°ÏÑ†.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_3826_Î∞úÏó¥, Î∂àÎ™ÖÏó¥.html\n",
      "\n",
      "üîç Query: Ìå®ÌòàÏ¶ùÏùò Ï†ïÏùòÏôÄ ÏπòÎ£å Ï†ëÍ∑ºÎ≤ïÏùÄ?\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_4736_Ìå®ÌòàÏ¶ù.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1657_3890_Ï†ÄÏπºÏäòÌòàÏ¶ù.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1912_4464_ÎπàÌòàÏùò Ï†ëÍ∑º.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1656_3900_Ïù¥ÏÉÅÏßÄÏßàÌòàÏ¶ùÏùò ÏπòÎ£å.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_4736_Ìå®ÌòàÏ¶ù.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1654_3885_ÎãπÎá®Ïùò ÏπòÎ£å.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1657_3889_Í≥†ÏπºÏäòÌòàÏ¶ù.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1758_4067_Ï†ÄÌòàÎãπ.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1656_3900_Ïù¥ÏÉÅÏßÄÏßàÌòàÏ¶ùÏùò ÏπòÎ£å.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1661_3905_Ï†ÑÏã†Í≤ΩÌôîÏ¶ù.html\n",
      "\n",
      "üîç Query: Î∞úÏó¥Ïùò Î≥ëÌÉúÏÉùÎ¶¨ ÏÑ§Î™ÖÌïòÏãúÏò§\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1654_3883_ÎãπÎá®Ïùò Í∞úÏöîÏôÄ Î≥ëÌÉúÏÉùÎ¶¨.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1868_4327_Î±ÄÎ¨ºÎ¶ºÍ≥º ÎèôÎ¨ºÎ¨ºÎ¶º.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1778_4161_ÎßêÎ°úÎ¶¨-Î∞îÏù¥Ïä§ Ï¶ùÌõÑÍµ∞.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1867_4342_ÌôîÏÉÅ.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1910_4458_Ï¢ÖÏñëÏö©Ìï¥Ï¶ùÌõÑÍµ∞.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2752_5760_ÎßàÎ•¥Ìåê Ï¶ùÌõÑÍµ∞.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1654_3883_ÎãπÎá®Ïùò Í∞úÏöîÏôÄ Î≥ëÌÉúÏÉùÎ¶¨.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1654_3883_ÎãπÎá®Ïùò Í∞úÏöîÏôÄ Î≥ëÌÉúÏÉùÎ¶¨.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1660_3913_Ìï≠Ïù∏ÏßÄÏßà Ï¶ùÌõÑÍµ∞.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1740_4032_Îã§ÌÉúÏûÑÏã†.html\n",
      "\n",
      "üîç Query: FeverÏùò Î≥ëÌÉúÏÉùÎ¶¨Î•º ÏÑ§Î™ÖÌïòÏãúÏò§.\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_3826_Î∞úÏó¥, Î∂àÎ™ÖÏó¥.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1643_3846_Ï§ëÏ¶ùÏó¥ÏÑ±ÌòàÏÜåÌåêÍ∞êÏÜåÏ¶ùÌõÑÍµ∞.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1775_4110_Ïã†ÏÉùÏïÑ ÏßàÌôò - Í∏∞ÌÉÄ.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_3826_Î∞úÏó¥, Î∂àÎ™ÖÏó¥.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2525_5699_SFTS virus.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1638_3853_Neutropenic fever.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2525_5699_SFTS virus.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2521_5659_Legionella pneumophila.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1638_3853_Neutropenic fever.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1641_3856_ÎùºÏûÑÎ≥ë, Ïû¨Í∑ÄÏó¥.html\n",
      "\n",
      "üîç Query: Ïã¨Î∂ÄÏ†ÑÏúºÎ°ú ÏûÖÏõêÌïú ÌôòÏûêÏùò Ï¥àÍ∏∞ ÌèâÍ∞Ä Ìï≠Î™©ÏùÄ?\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1888_4435_Ï†ïÏã†Í≥ºÏ†Å ÌèâÍ∞Ä.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1862_4330_ÏÑ†ÌÉùÏ†Å ÏàòÏà†Ïóê ÎåÄÌïú Î∞òÏùë.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1797_5451_Ïã¨Ìôî 1. Ïã¨Ï¥àÏùåÌåå.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1801_4190_Ïã¨Í∑ºÏóº.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1672_3928_ÌóàÌòàÏÑ± ÎáåÏ°∏Ï§ë.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1652_3895_Î∂ÄÏã†Í∏∞Îä•Ï†ÄÌïòÏ¶ù.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1648_3875_ÎÇ¥Î∂ÑÎπÑ ÏßàÌôòÏùò Ï†ëÍ∑º.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1696_3954_Ïô∏ÏÉÅÏùò ÏùëÍ∏âÏ≤òÏπò.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1888_4435_Ï†ïÏã†Í≥ºÏ†Å ÌèâÍ∞Ä.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1800_4195_Ïã¨Î∂ÄÏ†Ñ ÏõêÏù∏, Ï¶ùÏÉÅ, ÏßÑÎã®.html\n",
      "\n",
      "üîç Query: Ïã¨Î∂ÄÏ†ÑÏúºÎ°ú ÏûÖÏõêÌïú ÌôòÏûêÏóêÍ≤å Ï≤òÏùå ÏãúÌñâÌï¥Ïïº Ìï† Ï≤òÏπòÎäî?\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1696_3953_Ïã¨Ï†ïÏßÄ ÌõÑ Ìï©Î≥ëÏ¶ù.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1864_4329_ÏàòÏà† Ï†Ñ Ï≤òÏπò.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2440_4450_ÏßÄÏó≠ÏÇ¨ÌöåÏ†ïÏã†ÏùòÌïô.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1759_4083_Ï§ëÏ∂î Ïã†Í≤ΩÍ≥ÑÏùò Í∞êÏóº ÏßàÌôò.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1804_4172_Í∞êÏóº Ïã¨ÎÇ¥ÎßâÏóº.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1882_4401_ÌóåÌòàÏûê Í¥ÄÎ¶¨.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1647_3854_ÏÑ±Ïù∏Ïùò ÏòàÎ∞©Ï†ëÏ¢Ö.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1647_3854_ÏÑ±Ïù∏Ïùò ÏòàÎ∞©Ï†ëÏ¢Ö.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_4736_Ìå®ÌòàÏ¶ù.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1711_4015_ÏÑ±Ìè≠Ìñâ.html\n",
      "\n",
      "üîç Query: Í∏âÏÑ± Ïã¨Î∂ÄÏ†ÑÏúºÎ°ú ÏûÖÏõêÌïú ÌôòÏûêÏóêÍ≤å Ï≤òÏùå ÏãúÌñâÌï¥Ïïº Ìï† Ï≤òÏπòÎäî?\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1696_3953_Ïã¨Ï†ïÏßÄ ÌõÑ Ìï©Î≥ëÏ¶ù.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1864_4329_ÏàòÏà† Ï†Ñ Ï≤òÏπò.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2440_4450_ÏßÄÏó≠ÏÇ¨ÌöåÏ†ïÏã†ÏùòÌïô.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1711_4015_ÏÑ±Ìè≠Ìñâ.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1789_4131_Í∏âÏÑ± Í∞ÑÎ∂ÄÏ†Ñ.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1868_4327_Î±ÄÎ¨ºÎ¶ºÍ≥º ÎèôÎ¨ºÎ¨ºÎ¶º.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_4736_Ìå®ÌòàÏ¶ù.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1864_4329_ÏàòÏà† Ï†Ñ Ï≤òÏπò.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1804_4172_Í∞êÏóº Ïã¨ÎÇ¥ÎßâÏóº.html\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1864_4329_ÏàòÏà† Ï†Ñ Ï≤òÏπò.html\n"
     ]
    }
   ],
   "source": [
    "query_log = []\n",
    "\n",
    "for query in queries:\n",
    "    docs = retriever.invoke(query)\n",
    "    print(f\"\\nüîç Query: {query}\")\n",
    "\n",
    "    result_entry = {\"query\": query, \"results\": []}\n",
    "    \n",
    "    for doc in docs:\n",
    "        source = doc.metadata.get(\"source\", \"Unknown\")\n",
    "        excerpt = doc.page_content.replace(\"\\n\", \" \").strip()\n",
    "        result_entry[\"results\"].append({\n",
    "            \"source\": os.path.basename(source),\n",
    "            \"chunk_index\": doc.metadata.get(\"chunk_index\", 99),\n",
    "            \"total_chunks\": doc.metadata.get(\"total_chunks\", 99),\n",
    "            \"excerpt\": excerpt,\n",
    "        })\n",
    "        print(f\"  - {source}\")\n",
    "\n",
    "    query_log.append(result_entry)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd88be",
   "metadata": {},
   "source": [
    "# Self Rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21e1f592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sese\\anaconda3\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1400: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sese\\anaconda3\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1400: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sese\\anaconda3\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1400: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "### === Retrieval Grader ===\n",
    "\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(description=\"Documents are relevant to the question, 'yes' or 'no'\")\n",
    "\n",
    "retrieval_grader_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_retrieval_grader = retrieval_grader_llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "retrieval_grader_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \n",
    "     It does not need to be a stringent test. The goal is to filter out erroneous retrievals.\n",
    "     If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant.\n",
    "     Give a binary score 'yes' or 'no'.\"\"\"),\n",
    "    (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\")\n",
    "])\n",
    "\n",
    "retrieval_grader = retrieval_grader_prompt | structured_retrieval_grader\n",
    "\n",
    "\n",
    "### === Generation Chain (RAG) ===\n",
    "\n",
    "generator_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = rag_prompt | generator_llm | StrOutputParser()\n",
    "\n",
    "\n",
    "### === Hallucination Grader ===\n",
    "\n",
    "class GradeHallucinations(BaseModel):\n",
    "    binary_score: str = Field(description=\"Answer is grounded in the facts, 'yes' or 'no'\")\n",
    "\n",
    "hallucination_grader_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_hallu_grader = hallucination_grader_llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \n",
    "     If the key claims are reasonably inferred from the facts or are widely known and not contradicted, grade 'yes'.\n",
    "     Avoid penalizing common medical knowledge or minor elaborations. Grade only truly unsupported or conflicting claims as 'no'.\"\"\"),\n",
    "    (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\")\n",
    "])\n",
    "\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_hallu_grader\n",
    "\n",
    "\n",
    "### === Answer Grader ===\n",
    "\n",
    "class GradeAnswer(BaseModel):\n",
    "    binary_score: str = Field(description=\"Answer addresses the question, 'yes' or 'no'\")\n",
    "\n",
    "answer_grader_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_answer_grader = answer_grader_llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "answer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"\"\"You are a grader assessing whether an answer addresses / resolves a question.\n",
    "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer resolves the question.\"\"\"),\n",
    "    (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\")\n",
    "])\n",
    "\n",
    "answer_grader = answer_prompt | structured_answer_grader\n",
    "\n",
    "\n",
    "### === Question Rewriter ===\n",
    "\n",
    "question_rewriter_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"\"\"You are a question re-writer that converts an input question to a better version optimized for vectorstore retrieval.\n",
    "     Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"),\n",
    "    (\"human\", \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\")\n",
    "])\n",
    "\n",
    "question_rewriter = rewrite_prompt | question_rewriter_llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b8e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4e5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query: ÎéÖÍ∏∞Ïó¥Í≥º ÎπÑÏä∑Ìïú Îß§Í∞úÏ≤¥Î°ú Ïù∏Ìïú Í∞êÏóºÎ≥ëÏùÄ?\n",
      "Retrieved 10 docs, 2 relevant after grading.\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\2525_5684_Î™®Í∏∞ Îß§Í∞ú Í∞êÏóºÎ≥ë.html: Ï†úÎ™©: Î™®Í∏∞ Îß§Í∞ú Í∞êÏóºÎ≥ë\n",
      "\n",
      "Î∂ÑÎ•ò Î∞è Ï¶ùÏÉÅ \n",
      " \n",
      " \n",
      " ÏÜç(genus) \n",
      " Í¥ÄÎ†® ÏßàÎ≥ë Î∞è Î∂ÑÎ•ò \n",
      " Ï¶ùÏÉÅ \n",
      " ÎåÄÌëú Ïú†Ìñâ ÏßÄÏó≠ \n",
      " \n",
      " \n",
      " \n",
      " Anopheles \n",
      " : ÏñºÎ£©ÎÇ†Í∞úÎ™®Í∏∞, ÌïôÏßàÎ™®...\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1643_3848_Ïó¨Ìñâ Í¥ÄÎ†® Î∞îÏù¥Îü¨Ïä§ Í∞êÏóº.html: Ï†úÎ™©: Ïó¨Ìñâ Í¥ÄÎ†® Î∞îÏù¥Îü¨Ïä§ Í∞êÏóº\n",
      "\n",
      "ÎéÖÍ∏∞Ïó¥, ÏπòÏø§Íµ¨ÎãàÏïºÏó¥, ÏßÄÏπ¥ Î∞îÏù¥Îü¨Ïä§ Í∞êÏóºÏ¶ù, Ìô©Ïó¥, Î©îÎ•¥Ïä§Ïóê ÎåÄÌï¥ÏÑú Îã§Î£¨Îã§. Ïó¨ÌñâÎ†•Í≥º ÏûÑÏÉÅÏñëÏÉÅÏùÑ Î≥¥Í≥† Í∞ÄÎä•ÏÑ±Ïù¥ ÎÜíÏùÄ ÏßÑÎã®Î™ÖÏùÑ Í≥†Î•¥Îäî Î¨∏Ï†úÍ∞Ä ÏûêÏ£º...\n",
      "Generated answer: ÎéÖÍ∏∞Ïó¥Í≥º ÎπÑÏä∑Ìïú Îß§Í∞úÏ≤¥Î°ú Ïù∏Ìïú Í∞êÏóºÎ≥ëÏúºÎ°úÎäî ÏπòÏø§Íµ¨ÎãàÏïºÏó¥Í≥º ÏßÄÏπ¥ Î∞îÏù¥Îü¨Ïä§ Í∞êÏóºÏ¶ùÏù¥ ÏûàÏäµÎãàÎã§. Ïù¥Îì§ ÏßàÎ≥ëÏùÄ Î™®Îëê Aedes Î™®Í∏∞Ïóê ÏùòÌï¥ Ï†ÑÌååÎêòÎ©∞, Ïú†ÏÇ¨Ìïú Ï¶ùÏÉÅÏùÑ ÎÇòÌÉÄÎÉÖÎãàÎã§. ÎòêÌïú Ìô©Ïó¥ÎèÑ Î™®Í∏∞ Îß§Í∞ú Í∞êÏóºÎ≥ëÏúºÎ°ú Í¥ÄÎ†®Ïù¥ ÏûàÏäµÎãàÎã§.\n",
      "‚úÖ Answer is good and grounded.\n",
      "\n",
      "üîç Query: Î∂àÎ™ÖÏó¥ ÏßÑÎã® ÏàúÏÑúÎ•º ÏÑ§Î™ÖÌïòÏãúÏò§\n",
      "Retrieved 10 docs, 2 relevant after grading.\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_3826_Î∞úÏó¥, Î∂àÎ™ÖÏó¥.html: Ï†úÎ™©: Î∞úÏó¥, Î∂àÎ™ÖÏó¥\n",
      "\n",
      "Í∞êÏóºÏÑ± ÏßàÌôòÏóêÏÑú Ï£ºÎ°ú ÎèôÎ∞òÎêòÎäî Ï¶ùÏÉÅÏù∏ Î∞úÏó¥Í≥º Î∂àÎ™ÖÏó¥Ïóê ÎåÄÌï¥ Îã§Î£¨Îã§. ÏãúÌóòÏóê ÌäπÎ≥ÑÌûà ÎßéÏù¥ Ï∂úÏ†úÎêòÎäî Î∂ÄÎ∂ÑÏùÄ ÏïÑÎãàÎã§. Î∂àÎ™ÖÏó¥ ÌôòÏûêÏóêÏÑú Îã§ÏùåÏóê Ìï¥ÏïºÌï† Í≤ÄÏÇ¨, Ï°∞ÏπòÎ•º...\n",
      "  - C:\\Users\\Sese\\autosave\\ÏïåÎ†å Ïù¥Î°† Ï∂îÏ∂ú\\theory_texts\\1636_3826_Î∞úÏó¥, Î∂àÎ™ÖÏó¥.html: Ï†úÎ™©: Î∞úÏó¥, Î∂àÎ™ÖÏó¥\n",
      "\n",
      "1. Î∞úÏó¥(fever) \n",
      " 1) Ï≤¥Ïò® (body temperature) \n",
      " (1) ¬† Ï†ïÏÉÅ Íµ¨Í∞ïÏ≤¥Ïò®: 36.8 ¬± 0.4‚ÑÉ ¬†(6AM Í∏∞Ï§Ä) \n",
      " ‚ë† ÏßÅÏû•Ï≤¥Ïò®...\n",
      "Generated answer: Î∂àÎ™ÖÏó¥ ÏßÑÎã® ÏàúÏÑúÎäî Î®ºÏ†Ä ÌôòÏûêÏùò Î≥ëÎ†•Í≥º Ïã†Ï≤¥ Í≤ÄÏÇ¨Î•º ÌÜµÌï¥ ÏõêÏù∏ÏùÑ ÌååÏïÖÌïòÍ≥†, Í∞êÏóº, ÏóºÏ¶ù, Ï¢ÖÏñë Îì±Ïùò Í∞ÄÎä•ÏÑ±ÏùÑ Í≥†Î†§ÌïòÏó¨ Ï∂îÍ∞Ä Í≤ÄÏÇ¨Î•º ÏßÑÌñâÌïòÎäî Í≤ÉÏûÖÎãàÎã§. Ïù¥ÌõÑ ÌòàÏï° Í≤ÄÏÇ¨, ÏòÅÏÉÅ Í≤ÄÏÇ¨ Îì±ÏùÑ ÌÜµÌï¥ ÏõêÏù∏ÏùÑ Í∑úÎ™ÖÌïòÍ≥†, ÌïÑÏöîÏãú Ï†ÑÎ¨∏ÏùòÏôÄ ÌòëÎ†•ÌïòÏó¨ ÏßÑÎã®ÏùÑ ÌôïÏ†ïÌï©ÎãàÎã§. ÎßàÏßÄÎßâÏúºÎ°ú, ÏπòÎ£å Î∞©ÏïàÏùÑ Î™®ÏÉâÌïòÎ©∞ ÌôòÏûêÏùò ÏÉÅÌÉúÎ•º ÏßÄÏÜçÏ†ÅÏúºÎ°ú Î™®ÎãàÌÑ∞ÎßÅÌï©ÎãàÎã§.\n",
      "‚úÖ Answer is good and grounded.\n",
      "\n",
      "üîç Query: Ìå®ÌòàÏ¶ùÏùò Ï†ïÏùòÏôÄ ÏπòÎ£å Ï†ëÍ∑ºÎ≤ïÏùÄ?\n"
     ]
    }
   ],
   "source": [
    "def run_self_rag(question, retriever, rag_chain, retrieval_grader, hallucination_grader, answer_grader, question_rewriter, max_iter=5):\n",
    "    patience = max_iter\n",
    "    current_question = question\n",
    "\n",
    "    while patience > 0:\n",
    "        # 1. Retrieve\n",
    "        docs = retriever.invoke(current_question)\n",
    "        if not docs:\n",
    "            print(f\"No docs found for: {current_question}\")\n",
    "            current_question = question_rewriter.invoke({\"question\": current_question})\n",
    "            patience -= 1\n",
    "            continue\n",
    "\n",
    "        # 2. Grade documents\n",
    "        filtered_docs = []\n",
    "        for doc in docs:\n",
    "            score = retrieval_grader.invoke({\"question\": current_question, \"document\": doc.page_content})\n",
    "            if score.binary_score.lower() == \"yes\":\n",
    "                filtered_docs.append(doc)\n",
    "        print(f\"Retrieved {len(docs)} docs, {len(filtered_docs)} relevant after grading.\")\n",
    "        for filter_doc in filtered_docs:\n",
    "            print(f\"  - {filter_doc.metadata.get('source', 'Unknown')}: {filter_doc.page_content[:100]}...\")\n",
    "\n",
    "        if not filtered_docs:\n",
    "            print(\"No relevant docs after grading. Rewriting question...\")\n",
    "            current_question = question_rewriter.invoke({\"question\": current_question})\n",
    "            patience -= 1\n",
    "            continue\n",
    "\n",
    "        # 3. Generate answer\n",
    "        generation = rag_chain.invoke({\"context\": format_docs(filtered_docs), \"question\": current_question})\n",
    "        \n",
    "        print(f\"Generated answer: {generation}\")\n",
    "\n",
    "        # 4. Check hallucination\n",
    "        hallucination_score = hallucination_grader.invoke({\n",
    "            \"documents\": format_docs(filtered_docs),\n",
    "            \"generation\": generation\n",
    "        })\n",
    "\n",
    "        if hallucination_score.binary_score.lower() == \"no\":\n",
    "            print(\"Detected hallucination. Regenerating answer...\")\n",
    "            patience -= 1\n",
    "            continue\n",
    "\n",
    "        # 5. Check answer quality\n",
    "        answer_score = answer_grader.invoke({\n",
    "            \"question\": current_question,\n",
    "            \"generation\": generation\n",
    "        })\n",
    "\n",
    "        if answer_score.binary_score.lower() == \"yes\":\n",
    "            print(\"‚úÖ Answer is good and grounded.\")\n",
    "            return generation, current_question, filtered_docs\n",
    "        else:\n",
    "            print(\"Answer is not relevant enough. Rewriting question...\")\n",
    "            current_question = question_rewriter.invoke({\"question\": current_question})\n",
    "            patience -= 1\n",
    "\n",
    "    print(\"‚ùå Failed to generate a valid answer. Returning last try.\")\n",
    "    return generation, current_question, filtered_docs\n",
    "\n",
    "query_log = []\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nüîç Query: {query}\")\n",
    "    generation, used_question, used_docs = run_self_rag(\n",
    "        query,\n",
    "        retriever,\n",
    "        rag_chain,\n",
    "        retrieval_grader,\n",
    "        hallucination_grader,\n",
    "        answer_grader,\n",
    "        question_rewriter\n",
    "    )\n",
    "\n",
    "    result_entry = {\n",
    "        \"query\": query,\n",
    "        \"rewritten_query\": used_question,\n",
    "        \"answer\": generation,\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"source\": doc.metadata.get(\"source\", \"Unknown\"),\n",
    "                \"chunk_index\": doc.metadata.get(\"chunk_index\", 99),\n",
    "                \"excerpt\": doc.page_content.strip().replace(\"\\n\", \" \")\n",
    "            }\n",
    "            for doc in used_docs\n",
    "        ]\n",
    "    }\n",
    "    query_log.append(result_entry)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
