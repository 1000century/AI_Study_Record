{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000+0.0000j,  1.0000+0.0000j,  1.0000+0.0000j,  1.0000+0.0000j],\n",
      "        [ 0.5403+0.8415j,  0.9950+0.0998j,  0.9999+0.0100j,  1.0000+0.0010j],\n",
      "        [-0.4161+0.9093j,  0.9801+0.1987j,  0.9998+0.0200j,  1.0000+0.0020j],\n",
      "        [-0.9900+0.1411j,  0.9553+0.2955j,  0.9996+0.0300j,  1.0000+0.0030j],\n",
      "        [-0.6536-0.7568j,  0.9211+0.3894j,  0.9992+0.0400j,  1.0000+0.0040j],\n",
      "        [ 0.2837-0.9589j,  0.8776+0.4794j,  0.9988+0.0500j,  1.0000+0.0050j],\n",
      "        [ 0.9602-0.2794j,  0.8253+0.5646j,  0.9982+0.0600j,  1.0000+0.0060j],\n",
      "        [ 0.7539+0.6570j,  0.7648+0.6442j,  0.9976+0.0699j,  1.0000+0.0070j],\n",
      "        [-0.1455+0.9894j,  0.6967+0.7174j,  0.9968+0.0799j,  1.0000+0.0080j],\n",
      "        [-0.9111+0.4121j,  0.6216+0.7833j,  0.9960+0.0899j,  1.0000+0.0090j]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def precompute_theta_pos_frequencies(head_dim: int, seq_len:int, device:str, theta: float=10000.0):\n",
    "    assert head_dim % 2 == 0, \"dimension must be divisible by 2\"\n",
    "    theta_numerator = torch.arange(0,head_dim,2).float() # [0,2,4,6, ....]\n",
    "    theta = 1.0 / (theta ** (theta_numerator /head_dim)).to(device) # 각도 정해주기\n",
    "    \n",
    "    m = torch.arange(seq_len, device=device) # [0,1,2,3,4, ....]\n",
    "    \n",
    "    freqs = torch.outer(m, theta).float() # 외적 -> m이랑 세타를 외적함\n",
    "    \n",
    "    freqs_complex = torch.polar(torch.ones_like(freqs),freqs)\n",
    "    return freqs_complex\n",
    "\n",
    "head_dim = 8\n",
    "seq_len = 10\n",
    "device = 'cpu'\n",
    "\n",
    "freqs_complex = precompute_theta_pos_frequencies(head_dim, seq_len, device)\n",
    "print(freqs_complex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 x:\n",
      "tensor([[[ 1.0283,  1.3571,  0.7097,  1.4176, -0.7947,  1.0628,  0.1579,\n",
      "          -1.1376],\n",
      "         [ 0.2505, -0.5515, -1.4658,  0.2132, -0.8378,  0.0130,  0.0600,\n",
      "           0.2982],\n",
      "         [ 1.0666, -0.9124,  1.0255,  0.0243, -0.7689,  0.7426,  1.1425,\n",
      "           0.9992],\n",
      "         [ 1.9832,  0.9898,  2.4005,  0.4955,  0.6851,  2.2017,  1.3194,\n",
      "          -0.4922],\n",
      "         [-1.3652,  0.1174,  0.0676,  1.2757, -0.7534, -0.8079, -0.3021,\n",
      "          -0.5468],\n",
      "         [-0.1576,  0.6182,  1.5327,  1.0034,  1.0967,  1.1009,  3.2416,\n",
      "           0.2178],\n",
      "         [ 0.9898,  0.0973,  0.2729,  0.5641, -1.3300,  0.3752,  1.8387,\n",
      "          -1.3646],\n",
      "         [ 1.6059,  0.1259, -0.6587,  0.4747, -0.6078,  1.1926, -0.7239,\n",
      "           0.5323],\n",
      "         [ 0.1784, -0.6692, -0.7088, -0.8850, -3.2152, -0.6891, -0.8253,\n",
      "           0.9278],\n",
      "         [ 1.7650,  0.2146, -0.8469,  0.1316, -1.8610,  0.8300, -0.9973,\n",
      "           0.2113]],\n",
      "\n",
      "        [[ 0.9223,  1.8291,  2.8139, -0.3953,  0.2322, -0.3519, -0.1490,\n",
      "           0.8508],\n",
      "         [-0.1748, -0.9641, -0.0654,  0.5794, -1.0131, -0.7091,  0.0680,\n",
      "          -1.2173],\n",
      "         [ 0.2224, -1.5647,  0.4320, -0.8611,  1.1094, -2.2962,  0.2366,\n",
      "           2.2787],\n",
      "         [-1.5853, -1.1201,  0.7614, -1.3421,  0.9411, -0.3158,  0.5129,\n",
      "          -1.0163],\n",
      "         [ 0.1653,  0.0587,  0.6765,  1.5873,  0.9786,  0.0696, -2.0785,\n",
      "          -1.1750],\n",
      "         [ 1.6183, -0.2869, -0.3614, -1.3270, -1.2460,  0.6795, -0.7649,\n",
      "          -0.9557],\n",
      "         [-0.9930, -0.3242, -1.6530, -1.0138, -1.3197, -0.2939,  0.6913,\n",
      "           1.8626],\n",
      "         [-0.0245, -0.9973, -0.2268, -0.6231, -0.2891,  1.0109,  0.6191,\n",
      "           0.2046],\n",
      "         [-1.4537,  0.6422, -0.8687, -0.0324, -1.6696,  0.8017, -2.1464,\n",
      "           0.4000],\n",
      "         [ 0.4084, -0.2879,  1.9896, -0.3599,  0.6897,  0.5218, -0.1709,\n",
      "          -0.0534]]])\n",
      "\n",
      "계산된 freqs_complex:\n",
      "tensor([[ 1.0000+0.0000j,  1.0000+0.0000j,  1.0000+0.0000j,  1.0000+0.0000j],\n",
      "        [ 0.5403+0.8415j,  0.9950+0.0998j,  0.9999+0.0100j,  1.0000+0.0010j],\n",
      "        [-0.4161+0.9093j,  0.9801+0.1987j,  0.9998+0.0200j,  1.0000+0.0020j],\n",
      "        [-0.9900+0.1411j,  0.9553+0.2955j,  0.9996+0.0300j,  1.0000+0.0030j],\n",
      "        [-0.6536-0.7568j,  0.9211+0.3894j,  0.9992+0.0400j,  1.0000+0.0040j],\n",
      "        [ 0.2837-0.9589j,  0.8776+0.4794j,  0.9988+0.0500j,  1.0000+0.0050j],\n",
      "        [ 0.9602-0.2794j,  0.8253+0.5646j,  0.9982+0.0600j,  1.0000+0.0060j],\n",
      "        [ 0.7539+0.6570j,  0.7648+0.6442j,  0.9976+0.0699j,  1.0000+0.0070j],\n",
      "        [-0.1455+0.9894j,  0.6967+0.7174j,  0.9968+0.0799j,  1.0000+0.0080j],\n",
      "        [-0.9111+0.4121j,  0.6216+0.7833j,  0.9960+0.0899j,  1.0000+0.0090j]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(freqs_complex)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# rotary embedding 적용\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m x_rotated \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_complex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mrotary embedding 적용 후 x_rotated:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_rotated)\n",
      "Cell \u001b[1;32mIn[12], line 22\u001b[0m, in \u001b[0;36mapply_rotary_embeddings\u001b[1;34m(x, freqs_complex, device)\u001b[0m\n\u001b[0;32m     19\u001b[0m freqs_complex \u001b[38;5;241m=\u001b[39m freqs_complex\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 복소수 곱 연산\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m x_rotated \u001b[38;5;241m=\u001b[39m \u001b[43mx_complex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfreqs_complex\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 다시 실수 텐서로 변환 (마지막 차원이 2가 됨)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m x_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(x_rotated)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def precompute_theta_pos_frequencies(head_dim: int, seq_len: int, device: str, theta: float = 10000.0):\n",
    "    assert head_dim % 2 == 0, \"dimension must be divisible by 2\"\n",
    "    theta_numerator = torch.arange(0, head_dim, 2).float()  # [0,2,4,6, ...]\n",
    "    theta_vals = 1.0 / (theta ** (theta_numerator / head_dim)).to(device)  # 각도\n",
    "    m = torch.arange(seq_len, device=device)  # [0,1,2,...,seq_len-1]\n",
    "    freqs = torch.outer(m, theta_vals).float()  # m과 theta의 외적\n",
    "    freqs_complex = torch.polar(torch.ones_like(freqs), freqs)  # 복소수 표현 (1, angle)\n",
    "    return freqs_complex\n",
    "\n",
    "def apply_rotary_embeddings(x: torch.Tensor, freqs_complex: torch.Tensor, device: str):\n",
    "    # 마지막 차원(head_dim)을 2로 나누어 복소수 텐서로 변환합니다.\n",
    "    x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2))\n",
    "    \n",
    "    # freqs_complex의 차원 맞추기: (1, seq_len, 1, head_dim/2)\n",
    "    freqs_complex = freqs_complex.unsqueeze(0).unsqueeze(2)\n",
    "    \n",
    "    # 복소수 곱 연산\n",
    "    x_rotated = x_complex * freqs_complex\n",
    "    \n",
    "    # 다시 실수 텐서로 변환 (마지막 차원이 2가 됨)\n",
    "    x_out = torch.view_as_real(x_rotated)\n",
    "    \n",
    "    # 원래의 shape로 복원합니다.\n",
    "    x_out = x_out.reshape(*x.shape)\n",
    "    \n",
    "    return x_out.type_as(x).to(device)\n",
    "\n",
    "device = \"cpu\"  # 또는 \"cuda\" 사용 가능\n",
    "head_dim = 8  # 반드시 2의 배수여야 합니다.\n",
    "seq_len = 10\n",
    "batch_size = 2  # 예시 배치 사이즈\n",
    "\n",
    "# 임의의 데이터를 생성합니다. \n",
    "# shape: (batch_size, seq_len, head_dim)\n",
    "x = torch.randn(batch_size, seq_len, head_dim)\n",
    "print(\"원본 x:\")\n",
    "print(x)\n",
    "\n",
    "# Rotary embeddings을 위한 각도 주파수 복소수 값 계산\n",
    "freqs_complex = precompute_theta_pos_frequencies(head_dim, seq_len, device)\n",
    "print(\"\\n계산된 freqs_complex:\")\n",
    "print(freqs_complex)\n",
    "\n",
    "# rotary embedding 적용\n",
    "x_rotated = apply_rotary_embeddings(x, freqs_complex, device)\n",
    "print(\"\\nrotary embedding 적용 후 x_rotated:\")\n",
    "print(x_rotated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([0.0000, 1.5708, 3.1416])\n",
      "tensor([ 1.0000e+00+0.0000e+00j, -4.3711e-08+1.0000e+00j,\n",
      "        -1.0000e+00-8.7423e-08j])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# 각 복소수의 크기를 모두 1로 설정\n",
    "magnitudes = torch.ones(3)\n",
    "print(magnitudes)\n",
    "\n",
    "# 각 복소수의 각도를 0, π/2, π 라디안으로 설정\n",
    "angles = torch.tensor([0.0, math.pi/2, math.pi])\n",
    "print(angles)\n",
    "\n",
    "# polar를 사용하여 복소수 텐서를 생성합니다.\n",
    "complex_tensor = torch.polar(magnitudes, angles)\n",
    "print(complex_tensor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
